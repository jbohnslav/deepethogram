
# data augmentation parameters
augs:
  # randomly alter the brightness of the image. Larger values = more distortion
  brightness: 0.25
  # randomly alter the contrast of the image. Large values = more distortion
  contrast: 0.1
  # randomly alter hue of the image. large values = more distortion
  hue: 0.1
  # randomly alter saturation of the image. large values = more distortion
  saturation: 0.1
  # randomly change image to grayscale
  grayscale: 0.5
  # if not null, crop size will take random crops of the given shape during training, and center crop during inference.
  # Only use this if you know what you're doing: otherwise crop the videos before loading them into your project
  crop_size: null
  # IMPORTANT: either a single value (square output) or two values (height, width). All inputs to the models will be
  # resized to that shape. This should be as small as you can for a human to reasonably be able to tell the behavior.
  # decent defaults: 224, 256. Must be a multiple of 32 for resnet to work properly. Training and inference speed,
  # and VRAM used by the models are directly proportional to the input resolution.
  resize: null
  # use NVIDIA dali. experimental
  dali: false
  # deprecated
  random_resize: false
  # either a single value (pads all around) or four values (left, right, top, bottom). Use padding to increase both
  # height and width to be a multiple of 32
  pad: null
  # probability during training that the image will be flipped left-right. If this results in an image that could
  # actually appear in your training set, set it to 0.5. If it produces images that would never appear normally (for
  # example, if in your videos the animal is aligned to point to the left) set it to 0.
  LR: 0.5
  # probability during training that the image will be flipped up-down. If this results in an image that could
  #  # actually appear in your training set, set it to 0.5. Example: mouse in an open field looks reasonable flipped
  # upside down. By contrast, an animal walking on a treadmill will never appear upside-down, so it should be set to 0.
  UD: 0.0
  # The image during training will be randomly rotated +/- the below degrees.
  degrees: 10
  # This will be overwritten automatically. It is the mean and std deviation of the RGB channels of your dataset
  normalization:
    N: 0
    mean:
    - 0.5
    - 0.5
    - 0.5
    std:
    - 0.5
    - 0.5
    - 0.5